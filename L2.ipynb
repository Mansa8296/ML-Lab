{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2XwdNq0YOzcIV0KHUyT4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mansa8296/ML-Lab/blob/main/L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF2oijVPiSUN",
        "outputId": "a81b5345-11e8-4270-d9b6-6a4e68543216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Mammal\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def entropy(self, y):\n",
        "        class_counts = Counter(y)\n",
        "        entropy = 0\n",
        "        for label in class_counts:\n",
        "            prob = class_counts[label] / len(y)\n",
        "            entropy -= prob * np.log2(prob)\n",
        "        return entropy\n",
        "\n",
        "    def information_gain(self, X, y, feature_name):\n",
        "        entropy_parent = self.entropy(y)\n",
        "        unique_values = set(X[feature_name])\n",
        "        entropy_children = 0\n",
        "        for value in unique_values:\n",
        "            subset_y = y[X[feature_name] == value]\n",
        "            entropy_children += (len(subset_y) / len(y)) * self.entropy(subset_y)\n",
        "        return entropy_parent - entropy_children\n",
        "\n",
        "    def find_best_split(self, X, y, features):\n",
        "        best_feature = None\n",
        "        max_info_gain = -np.inf\n",
        "        for feature in features:\n",
        "            info_gain = self.information_gain(X, y, feature)\n",
        "            if info_gain > max_info_gain:\n",
        "                max_info_gain = info_gain\n",
        "                best_feature = feature\n",
        "        return best_feature\n",
        "\n",
        "    def fit(self, X, y, features):\n",
        "        self.tree = self.build_tree(X, y, features)\n",
        "\n",
        "    def build_tree(self, X, y, features):\n",
        "        if len(set(y)) == 1:  # If all samples have the same class, return a leaf node with that class\n",
        "            return y[0]\n",
        "        if len(features) == 0:  # If no features left to split on, return the majority class\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        best_feature = self.find_best_split(X, y, features)\n",
        "        tree = {best_feature: {}}\n",
        "        remaining_features = [feature for feature in features if feature != best_feature]\n",
        "        for value in set(X[best_feature]):\n",
        "            subset_index = X[best_feature] == value\n",
        "            subset_X = X[subset_index]\n",
        "            subset_y = y[subset_index]\n",
        "            tree[best_feature][value] = self.build_tree(subset_X, subset_y, remaining_features)\n",
        "        return tree\n",
        "\n",
        "    def predict_sample(self, sample):\n",
        "        current_node = self.tree\n",
        "        while isinstance(current_node, dict):\n",
        "            feature = list(current_node.keys())[0]\n",
        "            value = sample[feature]\n",
        "            current_node = current_node[feature][value]\n",
        "        return current_node\n",
        "\n",
        "# Example usage:\n",
        "X_train = pd.DataFrame({\n",
        "    'Has Fur': ['Yes', 'Yes', 'No', 'No', 'No', 'No'],\n",
        "    'Has Feathers': ['No', 'No', 'Yes', 'No', 'Yes', 'No'],\n",
        "    'Lays Eggs': ['No', 'No', 'No', 'Yes', 'Yes', 'Yes'],\n",
        "    'Can Fly': ['No', 'No', 'Yes', 'No', 'Yes', 'No']\n",
        "})\n",
        "\n",
        "y_train = np.array(['Mammal', 'Mammal', 'Bird', 'Reptile', 'Bird', 'Reptile'])\n",
        "\n",
        "features = ['Has Fur', 'Has Feathers', 'Lays Eggs', 'Can Fly']\n",
        "\n",
        "tree = DecisionTree()\n",
        "tree.fit(X_train, y_train, features)\n",
        "\n",
        "# Classify a new sample\n",
        "new_sample = {\n",
        "    'Has Fur': 'Yes',\n",
        "    'Has Feathers': 'No',\n",
        "    'Lays Eggs': 'No',\n",
        "    'Can Fly': 'No'\n",
        "}\n",
        "predicted_class = tree.predict_sample(new_sample)\n",
        "print(\"Predicted class:\", predicted_class)"
      ]
    }
  ]
}